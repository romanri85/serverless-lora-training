# Output path for training runs. Each training run makes a new directory in here.
output_dir = '/training_outputs/diffusion_pipe_training_runs/qwen_lora'

save_every_n_epochs = 20
epochs = 80
pipeline_stages = 1
micro_batch_size_per_gpu = 1  
gradient_accumulation_steps = 1
activation_checkpointing = true
dataset = 'examples/dataset.toml'
# Eval dataset for measuring loss on held-out data (smooth loss curve in TensorBoard).
# Place 5-15 captioned images in the eval_dataset_here/ folder.
eval_datasets = [
    {name = 'eval', config = 'examples/eval_dataset.toml'},
]

# eval settings
eval_every_n_epochs = 1
eval_before_first_step = true
eval_micro_batch_size_per_gpu = 1
eval_gradient_accumulation_steps = 1

[model]
type = 'qwen_image'
diffusers_path = '/models/Qwen-Image'
dtype = 'bfloat16'
transformer_dtype = 'float8'
timestep_sample_method = 'logit_normal'


[adapter]
type = "lora"  
rank = 32 
dtype = "bfloat16"   



[optimizer]
type = 'adamw_optimi'
lr = 2e-4
betas = [0.9, 0.99]
weight_decay = 0.01
eps = 1e-8
